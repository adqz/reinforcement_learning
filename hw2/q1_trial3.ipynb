{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_arguments(fn): # note that function as input\n",
    "    def new_function(*args,**kwargs): # we've seen these arguments before\n",
    "        print ('positional arguments:')\n",
    "        print (args)\n",
    "        print ('keyword arguments:')\n",
    "        print (kwargs)\n",
    "        return fn(*args,**kwargs) # return a function\n",
    "    return new_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenLake:\n",
    "    '''\n",
    "    A class written to solve Question 1 in HW2, ECE276C at UCSD\n",
    "    For more on frozenlake, check out - https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py\n",
    "    \n",
    "    The action have the following meanings:\n",
    "        LEFT = 0\n",
    "        DOWN = 1\n",
    "        RIGHT = 2\n",
    "        UP = 3\n",
    "    '''\n",
    "    def __init__(self, gamma):\n",
    "        '''\n",
    "        Initialize the frozen-lake environment\n",
    "        '''\n",
    "        assert isinstance(gamma, float) and 0.0<gamma<1.0, 'Invalid gamma'\n",
    "        \n",
    "        self.env = gym.make (\"FrozenLake-v0\")\n",
    "        self.gamma = gamma\n",
    "        self.numStates = self.env.observation_space.n\n",
    "        self.numActions = self.env.action_space.n\n",
    "        self.dt = 1\n",
    "        self.mapAction = {\n",
    "            0: 'left',\n",
    "            1: 'down',\n",
    "            2: 'right',\n",
    "            3: 'up',\n",
    "        }\n",
    "        self.initial_state = self.env.reset() #reset env and return initial state\n",
    "        print('Environment map:')\n",
    "        self.printMap()\n",
    "\n",
    "    def printMap(self):\n",
    "        print(self.env.desc)\n",
    "    \n",
    "    def generateRollout(self, policy=None, maxT = 100, initial_state = 0):\n",
    "        '''\n",
    "        A rollout is a series of (state, action) pairs which goes on until time maxT or we reach a terminal state.\n",
    "        A terminal state is reached when done = True in the following statement:\n",
    "        \n",
    "        >>> obs,r,done = env.step(action)\n",
    "        '''\n",
    "        assert isinstance(maxT, (int, float)), 'maxT needs to be int or float'\n",
    "        assert isinstance(initial_state, int)\n",
    "        assert initial_state in range(self.numStates)\n",
    "        \n",
    "        states = [initial_state]\n",
    "        actions = []\n",
    "        \n",
    "        t = 0\n",
    "        while(t < maxT):\n",
    "            if policy == None:\n",
    "                a = self.env.action_space.sample()\n",
    "            else:\n",
    "                a = policy(self, states[-1])\n",
    "            # Take a step using action a\n",
    "            next_state, r, done, info = env.step(a)\n",
    "            # Save next state and the action that led to it\n",
    "            states.append(next_state)\n",
    "            actions.append(a)\n",
    "            if done:\n",
    "                break\n",
    "            t = t + self.dt\n",
    "\n",
    "        assert len(states) - len(actions) == 1, 'Number of actions should be 1 less than number of states'\n",
    "        rollout = {\n",
    "            'state': states,\n",
    "            'action': actions,\n",
    "        }\n",
    "        \n",
    "        return rollout\n",
    "    \n",
    "#     @log_arguments\n",
    "    def TestPolicy(self, policy, num_trials=100, timeLimit = False, maxT=5000):\n",
    "        '''\n",
    "        Returns the average rate of successful episodes over 100 trials for a deterministic policy\n",
    "        '''\n",
    "        assert isinstance(policy, np.ndarray) and len(policy) == self.numStates\n",
    "        assert isinstance(num_trials, int) and num_trials>0\n",
    "        assert isinstance(timeLimit, bool)\n",
    "        assert isinstance(maxT, int) and maxT>0\n",
    "        \n",
    "        success_count = 0\n",
    "        for i in range(num_trials):\n",
    "            t = 0\n",
    "            state = int(self.env.reset()) #resetting state to initial position\n",
    "            while(True):\n",
    "                a = policy[state] #getting action from policy\n",
    "                next_state, r, done, info = self.env.step(a) #taking a step using action\n",
    "#                 print('next_state, r = ', next_state, r)\n",
    "                # Check if we reached goal, i.e. check for success\n",
    "                if (done and r == 1.0):\n",
    "                    success_count += 1\n",
    "                    break\n",
    "                \n",
    "                # Checking if we fell in a hole\n",
    "                if done:\n",
    "                    break\n",
    "                \n",
    "                if timeLimit and t>maxT:\n",
    "                    print('Max time exceeded. Breaking out of loop')\n",
    "                    break\n",
    "                \n",
    "                state = next_state ##### VERY IMPORTANT STEP!\n",
    "                t += self.dt\n",
    "        return success_count/num_trials\n",
    "\n",
    "    def LearnModel(self, num_samples = 100000):\n",
    "        '''\n",
    "        Returns transition probabilities and reward function\n",
    "        \n",
    "        p(s'|a, s) is accessed by typing p[s][a][s']\n",
    "        r(s,a,s') is accessed by typing r[s][a][s']\n",
    "        '''\n",
    "        assert isinstance(num_samples, int) and num_samples > 0\n",
    "        \n",
    "        self.env.reset()\n",
    "        p = np.zeros((self.numStates, self.numActions, self.numStates))\n",
    "        r = np.zeros((self.numStates, self.numActions, self.numStates))\n",
    "        counter = np.zeros((self.numStates, self.numActions))\n",
    "        self.count_s = np.zeros(self.numStates)\n",
    "        self.count_a = np.zeros(self.numActions)\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            s = np.random.randint(low = 0, high = self.numStates, dtype = int)\n",
    "            a = np.random.randint(low = 0, high = self.numActions, dtype = int)\n",
    "            self.count_s[s] += 1; self.count_a[a] += 1\n",
    "            \n",
    "            self.env.unwrapped.s = s #setting current state to randomly chosen state\n",
    "            s_prime, reward, _, _ = self.env.step(a)\n",
    "            \n",
    "            p[s][a][s_prime] += 1\n",
    "            r[s][a][s_prime] += reward\n",
    "            counter[s][a] += 1\n",
    "        \n",
    "        #use itertools instead\n",
    "        for s in range(self.numStates):\n",
    "            for a in range(self.numActions):\n",
    "                assert counter[s][a] != 0, 'Zero occurences of state-action pair. Cannot divide by 0'\n",
    "                p[s][a][:] = p[s][a][:]/counter[s][a]\n",
    "                r[s][a][:] = r[s][a][:]/counter[s][a]\n",
    "        \n",
    "        # Checking that probabilities sum to 1        \n",
    "        for s in range(self.numStates):\n",
    "            for a in range(self.numActions):\n",
    "                assert abs(sum(p[s,a,:])-1.0) < 1e-4, 'Probabilities dont sum to 1 --> %f' % sum(p[s,a,:])\n",
    "        \n",
    "        return p, r, counter\n",
    "    \n",
    "    def initializeValueAndPolicyFunction(self, initial_value = 0):\n",
    "        '''\n",
    "        Initializes Value and Policy function and returns them\n",
    "        All initial values for Value function are set to param initial_value\n",
    "        Initial values for Policy function are chosen randomly between [0, number of actions)\n",
    "        '''\n",
    "        assert isinstance(initial_value, (int, float))\n",
    "        \n",
    "        V = np.zeros((self.numStates))\n",
    "        policy = np.zeros((self.numStates))\n",
    "        \n",
    "        for s in range(self.numStates):\n",
    "            a = np.random.randint(low = 0, high = self.numActions, dtype = int)\n",
    "            V[s] = initial_value\n",
    "            policy[s] = a\n",
    "        \n",
    "        return V, policy\n",
    "    \n",
    "    def evaluatePolicy(self, V, policy):\n",
    "        '''\n",
    "        Evaluates policy for 1 iteration\n",
    "        '''\n",
    "        assert isinstance(V, np.ndarray) and len(V) == self.numStates\n",
    "        assert isinstance(policy, np.ndarray) and len(policy) == self.numStates\n",
    "        \n",
    "        gamma = self.gamma\n",
    "        V_new = np.zeros_like(V)\n",
    "        \n",
    "        for s in range(self.numStates):\n",
    "            a = policy[s]\n",
    "            pf_s = self.env.P[s][a] #prob distribution over states for taking action a at state s\n",
    "            # Calculating expected value of Value function coz of policy\n",
    "            exp_V = 0.0\n",
    "            for possible_sa_pairs in pf_s:\n",
    "                prob, next_state, r, _ = possible_sa_pairs\n",
    "                exp_V += prob*( r + gamma*V[next_state] ) \n",
    "            V_new[s] = exp_V\n",
    "        return V_new\n",
    "                \n",
    "    def checkPolicyConvergence(self, V_old, V_new, threshold = 1e-3):\n",
    "        '''\n",
    "        Checks for convergence by checking if the maximum difference between value of all states \n",
    "        is less than some threshold\n",
    "        '''\n",
    "        assert isinstance(threshold, float) and 0 < threshold < 1\n",
    "        assert isinstance(V_old, np.ndarray) and len(V_old) == self.numStates\n",
    "        assert isinstance(V_new, np.ndarray) and len(V_new) == self.numStates\n",
    "        \n",
    "        max_diff = np.max(np.abs(V_old - V_new))\n",
    "        success = max_diff<threshold\n",
    "        return success, max_diff\n",
    "    \n",
    "    def repeatedlyEvaluatePolicy(self, V, policy, verbose = False):\n",
    "        ''' Repeatedly evaluate policy until value function converges '''\n",
    "        assert isinstance(V, np.ndarray) and len(V) == self.numStates\n",
    "        assert isinstance(policy, np.ndarray) and len(policy) == self.numStates\n",
    "        \n",
    "        gamma = self.gamma\n",
    "        # 2. Repeated policy Evaluation\n",
    "        counter = 0\n",
    "        while (True):\n",
    "            # Step 1: Policy evaluation\n",
    "            V_new = fl.evaluatePolicy(V, policy=policy)\n",
    "            success, max_diff = fl.checkPolicyConvergence(V, V_new, threshold = 1e-3)\n",
    "            V = V_new\n",
    "            if success:\n",
    "                break\n",
    "            else:\n",
    "                counter += 1\n",
    "        if verbose:\n",
    "            print('Policy Evaluation converged in %d iterations' % counter)\n",
    "        return V\n",
    "    \n",
    "    def improvePolicy(self, V, policy, verbose = False):\n",
    "        ''' Improve the policy '''\n",
    "        assert isinstance(V, np.ndarray) and len(V) == self.numStates\n",
    "        assert isinstance(policy, np.ndarray) and len(policy) == self.numStates\n",
    "        \n",
    "        policy_stable = True\n",
    "        gamma = self.gamma\n",
    "\n",
    "        for s in range(self.numStates):\n",
    "            old_action = policy[s]\n",
    "            # Calculating q_pi(s,a) (from slides) for all actions over which we'll do argmax to find optimal action a\n",
    "            q_pi_sa = np.zeros((self.numActions))\n",
    "            for a in range(self.numActions):\n",
    "                pf_s = self.env.P[s][a] #prob distribution over states for taking action a at state s\n",
    "                expectation = 0.0\n",
    "                for possible_sa_pairs in pf_s:\n",
    "                    prob, next_state, r, _ = possible_sa_pairs\n",
    "                    expectation += prob*( r + gamma*V[next_state] ) \n",
    "                q_pi_sa[a] = expectation\n",
    "            # Updating policy\n",
    "            optimal_a = np.argmax(q_pi_sa)\n",
    "            policy[s] = optimal_a \n",
    "\n",
    "            if old_action != optimal_a:\n",
    "                policy_stable = False\n",
    "\n",
    "        # Now we have a new imporved policy. Let's test its success rate\n",
    "        success_rate = self.TestPolicy(policy, num_trials = 100, maxT = 5000)\n",
    "        \n",
    "        # Checking if policy has converged\n",
    "        if policy_stable:\n",
    "            return True, success_rate, policy\n",
    "        else:\n",
    "            return False, success_rate, policy\n",
    "    \n",
    "    def doPolicyIteration(self, verbose = False):\n",
    "        ''' Implement policy iteration '''\n",
    "        \n",
    "        # 1. Initialize policy and value function\n",
    "        V, policy = self.initializeValueAndPolicyFunction()\n",
    "        i, avg_success = 0, []\n",
    "        \n",
    "        for i in range(50):\n",
    "            # 2. Repeatedly evaluate policy till Value function converges\n",
    "            V = self.repeatedlyEvaluatePolicy(V, policy, verbose = verbose)\n",
    "\n",
    "            # 3. Policy Improvement\n",
    "            success, success_rate, policy = self.improvePolicy(V, policy)\n",
    "            avg_success.append(success_rate)\n",
    "            \n",
    "#             if success:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 i += 1\n",
    "#         if verbose:\n",
    "#             print('----->Policy improvement converged in %d iterations' % i)\n",
    "        \n",
    "        return V, policy, avg_success\n",
    "    \n",
    "    def doValueIteration(self, threshold = 1e-3, verbose = False):\n",
    "        ''' Implement value iteration '''\n",
    "        gamma = self.gamma\n",
    "        # 1. Initialize V\n",
    "        V, _ = self.initializeValueAndPolicyFunction()\n",
    "        # 2. Initialize delta\n",
    "        delta = np.inf\n",
    "        # 3. Improve V over all states and then repeat until delta is less than some threshold\n",
    "        i = 0\n",
    "        while(delta > threshold):\n",
    "            delta = 0\n",
    "            for s in range(self.numStates):\n",
    "                v = deepcopy(V[s])\n",
    "                allActionsResult = self.getExpectationOverAction(V, s)\n",
    "                assert allActionsResult.shape == (self.numActions, ), 'Needs to be a 1D ndarray'\n",
    "                V[s] = np.max(allActionsResult)\n",
    "                delta = max(delta, abs(v - V[s]))\n",
    "            \n",
    "            i += 1\n",
    "            # Getting policy from value function\n",
    "            policy = self.getPolicyFromValueFunction(V)\n",
    "            avg_success_rate = self.TestPolicy(policy, num_trials = 100, maxT = 5000)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Value iteration converged in {0} iterations with final delta = {1}'.format(i, delta))\n",
    "        \n",
    "        return V\n",
    "        \n",
    "    def getExpectationOverAction(self, V, s):\n",
    "        '''\n",
    "        Calculate the expected value of all actions at state s\n",
    "        '''\n",
    "        assert isinstance(s, int) and s in range(self.numStates)\n",
    "        assert isinstance(V, np.ndarray) and len(V) == self.numStates\n",
    "        \n",
    "        gamma = self.gamma\n",
    "        allActionsResult = np.zeros((self.numActions))\n",
    "        for a in range(self.numActions):\n",
    "            result_for_sa = self.env.P[s][a]\n",
    "            for sa in result_for_sa:\n",
    "                prob, next_state, r, _ = sa\n",
    "                allActionsResult[a] += prob*( r + gamma*V[next_state] )\n",
    "        return allActionsResult\n",
    "    \n",
    "    # POSSIBLE BUG -----> different gamma values can be used while calculating value function and deriving policy\n",
    "    \n",
    "    def getPolicyFromValueFunction(self, V):\n",
    "        '''\n",
    "        Deriving optimal policy using value function\n",
    "        '''\n",
    "        \n",
    "        gamma = self.gamma\n",
    "        # 1. Initialize policy\n",
    "        _, policy = self.initializeValueAndPolicyFunction()\n",
    "        # 2. Get optimal action for each state\n",
    "        for s in range(self.numActions):\n",
    "            allActionsResult = self.getExpectationOverAction(V, s)\n",
    "            assert allActionsResult.shape == (self.numActions, ), 'Needs to be a 1D ndarray'\n",
    "            policy[s] = np.argmax(allActionsResult)\n",
    "        return policy\n",
    "    \n",
    "    def plotPolicy(self, policy):\n",
    "        '''\n",
    "        Plot policy in words\n",
    "        '''\n",
    "        assert isinstance(policy, np.ndarray) and len(policy) == self.numStates\n",
    "        \n",
    "        for i, s in enumerate(range(self.numStates), 1):\n",
    "            a = policy[s]\n",
    "            print(self.mapAction[a] + '\\t', end='')\n",
    "            if i%4 == 0:\n",
    "                print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment map:\n",
      "[[b'S' b'F' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'H']\n",
      " [b'H' b'F' b'F' b'G']]\n",
      "\n",
      "Success Rate for policy is: 0.020\n"
     ]
    }
   ],
   "source": [
    "fl = FrozenLake(gamma = 0.9)\n",
    "# Forming test policy\n",
    "policyTest = np.zeros((fl.numStates))\n",
    "for s in range(fl.numStates):\n",
    "    policyTest[s] = (s+1)%4\n",
    "\n",
    "success_rate = fl.TestPolicy(policyTest, num_trials = 100, maxT = 5000)\n",
    "print('\\nSuccess Rate for policy is: %.3f' % (success_rate))\n",
    "# p, r, counter = fl.LearnModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Average success rate vs iterations')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "V, policy, avg_success = fl.doPolicyIteration(verbose=False)\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(range(len(avg_success)), avg_success, '-o')\n",
    "axs.set_title('Average success rate vs iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\tup\tleft\tup\t\n",
      "\n",
      "left\tleft\tleft\tleft\t\n",
      "\n",
      "up\tdown\tleft\tleft\t\n",
      "\n",
      "left\tright\tdown\tleft\t\n",
      "\n",
      "[[0. 3. 0. 3.]\n",
      " [0. 0. 0. 0.]\n",
      " [3. 1. 0. 0.]\n",
      " [0. 2. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "fl.plotPolicy(policy)\n",
    "print(policy.reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece276c_venv",
   "language": "python",
   "name": "ece276c_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
